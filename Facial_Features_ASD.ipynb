{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "i-ZGK44VLcJ9"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "fe2305119184495d8b0768ec4dda030d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51003f4cb6dd46be91caebfa15737689",
       "IPY_MODEL_c84c0f80d5b1459f952730b3e7619ac7",
       "IPY_MODEL_cf02495ab93d4921a268c421542d80ea"
      ],
      "layout": "IPY_MODEL_20e908cd324247b5b2af4e9de57347de"
     }
    },
    "51003f4cb6dd46be91caebfa15737689": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0842c0e5f2c468198ba35818c3ab741",
      "placeholder": "​",
      "style": "IPY_MODEL_4d3efce1fbdc4e75b4af1ead8af34e67",
      "value": "100%"
     }
    },
    "c84c0f80d5b1459f952730b3e7619ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7f1b8bc0c5745b98a789d308bbf32a5",
      "max": 111898327,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59a8da69c2594f869b824320ee1e854c",
      "value": 111898327
     }
    },
    "cf02495ab93d4921a268c421542d80ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4cd0b6da4384bdb942108d43a44e3a7",
      "placeholder": "​",
      "style": "IPY_MODEL_015d03a0dfbe431b9b44ca85fdc0542f",
      "value": " 107M/107M [00:00&lt;00:00, 188MB/s]"
     }
    },
    "20e908cd324247b5b2af4e9de57347de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0842c0e5f2c468198ba35818c3ab741": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d3efce1fbdc4e75b4af1ead8af34e67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7f1b8bc0c5745b98a789d308bbf32a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59a8da69c2594f869b824320ee1e854c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c4cd0b6da4384bdb942108d43a44e3a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "015d03a0dfbe431b9b44ca85fdc0542f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Temporary"
   ],
   "metadata": {
    "id": "2KACaQpMYqPO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "id": "qeGT-9rZQs-Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Utilities\n",
    "#!pip install gwpy --quiet\n",
    "#!pip install facenet-pytorch --quiet\n",
    "#!pip install seaborn\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ntpmczAHa8w",
    "outputId": "d612a78c-d179-45be-e618-23ee7e336bcb",
    "ExecuteTime": {
     "end_time": "2024-01-20T20:56:16.344729200Z",
     "start_time": "2024-01-20T20:56:11.722941400Z"
    }
   },
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Collecting seaborn\r\n",
      "  Downloading seaborn-0.13.1-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from seaborn) (1.26.0)\r\n",
      "Requirement already satisfied: pandas>=1.2 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from seaborn) (2.1.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from seaborn) (3.8.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.0.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/luishenrique/miniconda3/envs/ambPython311/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\r\n",
      "Downloading seaborn-0.13.1-py3-none-any.whl (294 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m294.8/294.8 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: seaborn\r\n",
      "Successfully installed seaborn-0.13.1\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dados\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "\n",
    "#data processing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import v2\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#data analisis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             accuracy_score, precision_score,\n",
    "                             recall_score, f1_score)\n",
    "\n",
    "#!git clone https://github.com/ox-vgg/vgg_face2.git\n",
    "\n"
   ],
   "metadata": {
    "id": "wCN_3quuFNaa",
    "ExecuteTime": {
     "end_time": "2024-01-20T20:56:44.158946600Z",
     "start_time": "2024-01-20T20:56:44.026446700Z"
    }
   },
   "execution_count": 135,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setting device \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {
    "id": "StcWFNxa1b8I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = \"./images/train\"\n",
    "path_tensor = './tensor_images/'\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "size_img = 160      #facenet-pytorch vggface2 size\n",
    "margin = 20\n",
    "batch_size = 32\n",
    "workers = 2"
   ],
   "metadata": {
    "id": "3A3Abu451bnJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Downloading Dataset"
   ],
   "metadata": {
    "id": "G4YZpJc0FN2I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def downloading_dataset():\n",
    "    if not Path(\"./images\").exists():\n",
    "        Path(\"./images\").mkdir()\n",
    "\n",
    "    # Baixando o arquivo zip do repositório\n",
    "    !wget https://github.com/mm909/Kaggle-Autism/archive/refs/heads/master.zip\n",
    "    \n",
    "    # Extraindo o conteúdo da pasta cleanData\n",
    "    !unzip master.zip Kaggle-Autism-master/data/* -d ./images/ > /dev/null 2>&1\n",
    "    \n",
    "    # Movendo o conteúdo para o diretório desejado\n",
    "    !mv ./images/Kaggle-Autism-master/data/* ./images/ > /dev/null 2>&1\n",
    "    \n",
    "    # Removendo arquivos desnecessários\n",
    "    !rm -r ./Kaggle-Autism-master > /dev/null 2>&1\n",
    "    !rm master.zip > /dev/null 2>&1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Data"
   ],
   "metadata": {
    "id": "6aR1s1NPLsPv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resizing and normalizing"
   ],
   "metadata": {
    "id": "7Vi0LpYObmrU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!rm -r tensor_images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def dataset_transform_and_save(path_tensor, tensor_name, transform):\n",
    "  try:\n",
    "    print(\"Tensor loaded\")\n",
    "    return  torch.load(path_tensor + tensor_name)\n",
    "  except FileNotFoundError:\n",
    "    os.makedirs(path_tensor, exist_ok=True)\n",
    "    print(\"Directory created\")\n",
    "\n",
    "  ds = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "  try:\n",
    "    torch.save(dataset, path_tensor + tensor_name)\n",
    "    print(\"tensor saved\")\n",
    "  except Exception:\n",
    "    print(\"tensor not saved\")\n",
    "\n",
    "  return ds"
   ],
   "metadata": {
    "id": "gjEmFMeOhRXo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_mean_and_std():\n",
    "    data_mean =[]\n",
    "    data_std = []\n",
    "    for i, (image, label) in enumerate(initial_dataset):\n",
    "        mt = torch.mean(image, dim=(1, 2))\n",
    "        st = torch.std(image, dim=(1, 2))\n",
    "    \n",
    "        #appended to the list\n",
    "        data_mean.append(mt)\n",
    "        data_std.append(st)\n",
    "\n",
    "    m = np.array(data_mean).mean(axis =0).astype(\"float32\").tolist()\n",
    "    s  = np.array(data_std).mean(axis=0).astype(\"float32\").tolist()\n",
    "    \n",
    "    #saving into a csv to decresase need to future calculations\n",
    "    df = pd.DataFrame({'mean': m, 'std': s})\n",
    "    df.to_csv('mean_std')\n",
    "    return m, s\n",
    "\n",
    "def load_mean_std():\n",
    "    if not Path(\"mean_std.csv\").exists():\n",
    "        return calculate_mean_and_std()\n",
    "        \n",
    "    a = pd.read_csv('mean_std')\n",
    "    m = a['mean'].values\n",
    "    s = a['std'].values\n",
    "    return m,s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "initial_transform = v2.Compose([\n",
    "      v2.Resize(size=(size_img, size_img)),\n",
    "      v2.RandomHorizontalFlip(),\n",
    "      v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "])\n",
    "\n",
    "mean,std = load_mean_std()\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    initial_transform,\n",
    "    transforms.Normalize(mean, std),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    initial_transform,\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transforming tensors"
   ],
   "metadata": {
    "id": "02QacMt-cOEM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "resized_tensor = 'loaded_tensors_resized'\n",
    "normalized_tensor = 'loaded_tensors_normalized'\n",
    "\n",
    "initial_dataset = dataset_transform_and_save(path_tensor, resized_tensor, initial_transform)\n",
    "dataset = dataset_transform_and_save(path_tensor,normalized_tensor, data_transform)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kh15-l_pJXYk",
    "outputId": "adef0740-246b-4d15-c8e4-50ace83f0bd2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Print batch"
   ],
   "metadata": {
    "id": "vSkSykp3aH9U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers = 2,\n",
    "                                         collate_fn=training.collate_pil)\n",
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)\n",
    "\n",
    "image_batch, labels_batch = data\n",
    "\n",
    "img = torchvision.utils.make_grid(image_batch)\n",
    "img = np.transpose(img, (1,2,0))\n",
    "\n",
    "plt.figure(figsize=(5,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "ROCEk_lQlTnA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN"
   ],
   "metadata": {
    "id": "FD5Mow4OSbTE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading pre-trained ai with facial recognition"
   ],
   "metadata": {
    "id": "oI2uz5tmdseu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained='vggface2',\n",
    "    num_classes=len(dataset.class_to_idx)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, [8, 15, 30])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "fe2305119184495d8b0768ec4dda030d",
      "51003f4cb6dd46be91caebfa15737689",
      "c84c0f80d5b1459f952730b3e7619ac7",
      "cf02495ab93d4921a268c421542d80ea",
      "20e908cd324247b5b2af4e9de57347de",
      "f0842c0e5f2c468198ba35818c3ab741",
      "4d3efce1fbdc4e75b4af1ead8af34e67",
      "d7f1b8bc0c5745b98a789d308bbf32a5",
      "59a8da69c2594f869b824320ee1e854c",
      "c4cd0b6da4384bdb942108d43a44e3a7",
      "015d03a0dfbe431b9b44ca85fdc0542f"
     ]
    },
    "id": "ONy88uDZ92Mh",
    "outputId": "b2775812-d2c8-4548-8b45-5c14d9a3bcae"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing data and metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "img_inds = np.arange(len(dataset))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
    "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_inds)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_inds)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'acc': training.accuracy\n",
    "}"
   ],
   "metadata": {
    "id": "mwpMpMOd_Ef7",
    "ExecuteTime": {
     "end_time": "2024-01-20T20:27:50.741242100Z",
     "start_time": "2024-01-20T20:27:50.733705300Z"
    }
   },
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    writer = SummaryWriter()\n",
    "    writer.iteration, writer.interval = 0, 10\n",
    "    \n",
    "    print('\\n\\nInitial')\n",
    "    print('-' * 10)\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "        print('-' * 10)\n",
    "    \n",
    "        resnet.train()\n",
    "        training.pass_epoch(\n",
    "            resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "            batch_metrics=metrics, show_running=True, device=device,\n",
    "            writer=writer\n",
    "        )\n",
    "    \n",
    "        resnet.eval()\n",
    "        training.pass_epoch(\n",
    "            resnet, loss_fn, val_loader,\n",
    "            batch_metrics=metrics, show_running=True, device=device,\n",
    "            writer=writer\n",
    "        )\n",
    "        \n",
    "    writer.close()\n",
    "    torch.save(resnet.state_dict(), 'trained_model.pth')\n",
    "\n",
    "\n",
    "train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWsKWVxt_IkU",
    "outputId": "18ab5abd-ca9e-4184-ac32-7bba76091788"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "InceptionResnetV1(\n  (conv2d_1a): BasicConv2d(\n    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_2a): BasicConv2d(\n    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_2b): BasicConv2d(\n    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2d_3b): BasicConv2d(\n    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_4a): BasicConv2d(\n    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_4b): BasicConv2d(\n    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (repeat_1): Sequential(\n    (0): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (mixed_6a): Mixed_6a(\n    (branch0): BasicConv2d(\n      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (repeat_2): Sequential(\n    (0): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (5): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (6): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (7): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (8): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (9): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (mixed_7a): Mixed_7a(\n    (branch0): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (repeat_3): Sequential(\n    (0): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (block8): Block8(\n    (branch0): BasicConv2d(\n      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n  (dropout): Dropout(p=0.6, inplace=False)\n  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (logits): Linear(in_features=512, out_features=2, bias=True)\n)"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained=None,  # Desativar o carregamento automático de pesos pré-treinados\n",
    "    num_classes=len(dataset.class_to_idx)\n",
    ").to(device)\n",
    "checkpoint = torch.load(\"trained_model.pth\")\n",
    "\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T20:32:25.213997200Z",
     "start_time": "2024-01-20T20:32:24.026780300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions for analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "photos_paths = []\n",
    "\n",
    "def read_photos(image_folder_path, file_extension):\n",
    "    photos_tensors = []\n",
    "    \n",
    "    files = os.listdir(image_folder_path)\n",
    "    photos_end = [arquivo for arquivo in files if arquivo.lower().endswith(file_extension)]\n",
    "    for photo in photos_end:\n",
    "        photo_path = os.path.join(image_folder_path, photo)\n",
    "        photos_paths.append(photo_path)\n",
    "        img_tensor = data_transform(Image.open(photo_path)).unsqueeze(0).to(device)\n",
    "        photos_tensors.append(img_tensor)\n",
    "        \n",
    "    return photos_tensors\n",
    "\n",
    "\n",
    "def inference(input_img):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_img)\n",
    "\n",
    "    prob = torch.nn.functional.softmax(output[0], dim=0).cpu()\n",
    "    return predict(torch.argmax(prob).item()), prob.numpy().tolist()\n",
    "\n",
    "\n",
    "def predict(prob):\n",
    "    return 'autistic' if prob == 0 else 'non-autistic'\n",
    "def print_photos(probabilities, photo_tensor, num, mode):   \n",
    "    if mode == 'tensor':\n",
    "        photo = np.array(photo_tensor.to('cpu').squeeze(0))\n",
    "        photo = np.transpose(photo, (1,2,0))\n",
    "    else:\n",
    "        photo = Image.open(photos_paths[num])\n",
    "    \n",
    "    plt.title(f\"{probabilities[0]}\\nAutistic: {probabilities[1][0]:.6f}\\nNon-Autistic: {probabilities[1][1]:.6f}\")\n",
    "    plt.imshow(photo)\n",
    "    plt.axis('off')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T20:34:57.332774400Z",
     "start_time": "2024-01-20T20:34:57.269417700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Infer and save individual image batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_and_save_img(path_test_photos,file_name,file_extension,mode):\n",
    "    test_photos = read_photos(path_test_photos,file_extension)\n",
    "\n",
    "    for h, photo_tensor in enumerate(test_photos):\n",
    "        if h >= 18:\n",
    "            break\n",
    "        result = inference(photo_tensor)\n",
    "        test_data.append(result)\n",
    "        print_photos(result,photo_tensor,h, mode)\n",
    "        plt.savefig(path_test_photos + f'/{file_name}{h}', dpi = 100)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "test_data = []\n",
    "test_and_save_img('path', 'new_file_name', 'jpeg', 'tensor') ##path, save_name, extension, mode: (tensor, photo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "            Label   Au prob  Non-Au prob\n0        autistic  0.926708     0.073292\n1        autistic  0.945626     0.054374\n2        autistic  0.858732     0.141268\n3    non-autistic  0.085972     0.914028\n4    non-autistic  0.159772     0.840228\n..            ...       ...          ...\n275  non-autistic  0.005912     0.994089\n276      autistic  0.913286     0.086714\n277  non-autistic  0.211696     0.788304\n278  non-autistic  0.055580     0.944420\n279      autistic  0.754147     0.245853\n\n[280 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Au prob</th>\n      <th>Non-Au prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>autistic</td>\n      <td>0.926708</td>\n      <td>0.073292</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>autistic</td>\n      <td>0.945626</td>\n      <td>0.054374</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>autistic</td>\n      <td>0.858732</td>\n      <td>0.141268</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>non-autistic</td>\n      <td>0.085972</td>\n      <td>0.914028</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>non-autistic</td>\n      <td>0.159772</td>\n      <td>0.840228</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>non-autistic</td>\n      <td>0.005912</td>\n      <td>0.994089</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>autistic</td>\n      <td>0.913286</td>\n      <td>0.086714</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>non-autistic</td>\n      <td>0.211696</td>\n      <td>0.788304</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>non-autistic</td>\n      <td>0.055580</td>\n      <td>0.944420</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>autistic</td>\n      <td>0.754147</td>\n      <td>0.245853</td>\n    </tr>\n  </tbody>\n</table>\n<p>280 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autistic = read_photos('./images/test/Autistic','jpg')\n",
    "non_autistic = read_photos('./images/test/Non_Autistic','jpg')\n",
    "\n",
    "\n",
    "def evaluate(eval_tensor, label):\n",
    "    global true_autistic, true_non_autistic, false_non_autistic, false_autistic\n",
    "    for j, photo_tensors in enumerate(eval_tensor):\n",
    "        if j>= 500:\n",
    "            break\n",
    "        result1 = inference(photo_tensors)\n",
    "        gen_data.append(result1)\n",
    "        if result1[0] == 'autistic' and label == 'autistic':\n",
    "            true_autistic = true_autistic + 1\n",
    "        elif result1[0] == 'non-autistic' and label == 'non-autistic':\n",
    "            true_non_autistic = true_non_autistic + 1\n",
    "        elif result1[0] == 'non-autistic':\n",
    "            false_non_autistic = false_non_autistic + 1\n",
    "        else:\n",
    "            false_autistic = false_autistic + 1\n",
    "            \n",
    "            \n",
    "gen_data = []\n",
    "\n",
    "true_autistic = 0\n",
    "true_non_autistic = 0\n",
    "false_non_autistic = 0\n",
    "false_autistic = 0\n",
    "\n",
    "evaluate(autistic, 'autistic')\n",
    "evaluate(non_autistic, 'non-autistic')\n",
    "\n",
    "\n",
    "labels = [item[0] for item in gen_data]\n",
    "au_prob = [item[1][0] for item in gen_data]\n",
    "non_au_prob = [item[1][1] for item in gen_data]\n",
    "\n",
    "# Criar o DataFrame\n",
    "gen_df = pd.DataFrame({'Label': labels, 'Au prob': au_prob, 'Non-Au prob': non_au_prob})\n",
    "gen_df.to_csv('generate_test_data')\n",
    "\n",
    "gen_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T21:07:36.512484700Z",
     "start_time": "2024-01-20T21:07:25.608744900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_autistic = false_autistic + true_autistic\n",
    "total_non_autistic = false_non_autistic + true_non_autistic\n",
    "total = total_autistic + total_non_autistic\n",
    "\n",
    "FN = false_autistic + false_non_autistic \n",
    "TP = true_autistic + true_non_autistic\n",
    "hit_rate = TP/total\n",
    "miss_rate = FN/total\n",
    "\n",
    "results_dic = {\n",
    "    'true_autistic': [true_autistic],\n",
    "    'true_non_autistic': [true_non_autistic],\n",
    "    'total_autistic': [total_autistic],\n",
    "    'false_non_autistic': [false_non_autistic],\n",
    "    'false_autistic': [false_autistic],\n",
    "    'total': [total],\n",
    "    'TP': [TP],\n",
    "    'FN': [FN],\n",
    "    'hit_rate': [hit_rate],\n",
    "    'miss_rate': [miss_rate],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dic)\n",
    "results_df= results_df.T.reset_index()\n",
    "results_df.columns = ['Name', 'Value']\n",
    "results_df.to_csv('test_results')\n",
    "\n",
    "print(f\"hit: {TP}  miss: {FN}    |   total: {total}\\n\")\n",
    "print(f\"autistic hit: {true_autistic}   autistic miss: {false_non_autistic}    |   total: {total/2}\\n\")\n",
    "print(f\"non autistic hit: {true_non_autistic}   non autistic miss: {false_autistic}    |   total: {total/2}\\n\")\n",
    "print(f\"hit rate: {hit_rate}  miss rate: {miss_rate}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criar a matriz de confusão\n",
    "conf_matrix_data = [[true_non_autistic, false_autistic],\n",
    "                    [false_non_autistic, true_autistic]]\n",
    "\n",
    "# Criar um DataFrame a partir da matriz de confusão\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix_data, columns=['Predicted Non-Autistic', 'Predicted Autistic'],\n",
    "                               index=['Actual Non-Autistic', 'Actual Autistic'])\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap='RdBu', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T20:58:09.361753500Z",
     "start_time": "2024-01-20T20:58:09.044183600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Precision: 0.79\n",
      "Recall: 0.76\n",
      "F1 Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "#other metrics\n",
    "accuracy = (true_autistic + true_non_autistic) / total\n",
    "precision = true_autistic / (true_autistic + false_autistic)\n",
    "recall = true_autistic / (true_autistic + false_non_autistic)\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Exibir métricas\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T21:00:52.478229800Z",
     "start_time": "2024-01-20T21:00:52.393822500Z"
    }
   }
  }
 ]
}
